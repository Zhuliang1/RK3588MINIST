{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0382bb-e558-4379-a785-64bfc3072aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#采用CPU进行训练\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def data_fetch_preprocessing():\n",
    "    train_image = open('train-images.idx3-ubyte', 'rb')\n",
    "    test_image = open('t10k-images.idx3-ubyte', 'rb')\n",
    "    train_label = open('train-labels.idx1-ubyte', 'rb')\n",
    "    test_label = open('t10k-labels.idx1-ubyte', 'rb')\n",
    "\n",
    "    magic, n = struct.unpack('>II',\n",
    "                             train_label.read(8))\n",
    "    # 原始数据的标签\n",
    "    y_train_label = np.array(np.fromfile(train_label,\n",
    "                                         dtype=np.uint8), ndmin=1)\n",
    "    y_train = np.ones((10, 60000)) * 0.01\n",
    "    for i in range(60000):\n",
    "        y_train[y_train_label[i]][i] = 0.99\n",
    "\n",
    "    # 测试数据的标签\n",
    "    magic_t, n_t = struct.unpack('>II',\n",
    "                                 test_label.read(8))\n",
    "    y_test = np.fromfile(test_label,\n",
    "                         dtype=np.uint8).reshape(10000, 1)\n",
    "    # print(y_train[0])\n",
    "    # 训练数据共有60000个\n",
    "    # print(len(labels))\n",
    "    magic, num, rows, cols = struct.unpack('>IIII', train_image.read(16))\n",
    "    x_train = np.fromfile(train_image, dtype=np.uint8).reshape(len(y_train_label), 784)\n",
    "\n",
    "    magic_2, num_2, rows_2, cols_2 = struct.unpack('>IIII', test_image.read(16))\n",
    "    x_test = np.fromfile(test_image, dtype=np.uint8).reshape(len(y_test), 784)\n",
    "    # print(x_train.shape)\n",
    "    # 可以通过这个函数观察图像\n",
    "    # data=x_train[:,0].reshape(28,28)\n",
    "    # plt.imshow(data,cmap='Greys',interpolation=None)\n",
    "    # plt.show()\n",
    "\n",
    "    # 关闭打开的文件\n",
    "    train_image.close()\n",
    "    train_label.close()\n",
    "    test_image.close()\n",
    "    test_label.close()\n",
    "\n",
    "    return x_train, y_train_label, x_test, y_test\n",
    "\n",
    "\n",
    "class convolution_neural_network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convolution_neural_network, self).__init__()\n",
    "\n",
    "        # 定义卷积层\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0),  # 28x28x1-->24x24x6\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 12x12x6\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),  # 8x8x16\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # 4x4x16\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=256, out_features=120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 获取数据\n",
    "    x_train, y_train, x_test, y_test = data_fetch_preprocessing()\n",
    "    x_train = x_train.reshape(60000, 1, 28, 28)\n",
    "    # 建立模型实例\n",
    "    LeNet = convolution_neural_network() \n",
    "    ##加入判断是CPU训练还是GPU训练\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    LeNet.to(device)\n",
    "\n",
    "    # plt.imshow(x_train[2][0], cmap='Greys', interpolation=None)\n",
    "    # plt.show()\n",
    "    # 交叉熵损失函数\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    loss_list = []\n",
    "    optimizer = optim.Adam(params=LeNet.parameters(), lr=0.001)\n",
    "    # epoch = 5\n",
    "    for e in range(3):\n",
    "        precision = 0\n",
    "        for i in range(60000):\n",
    "            prediction = LeNet(torch.tensor(x_train[i]).float().reshape(-1, 1, 28, 28))\n",
    "            # print(prediction)\n",
    "            # print(torch.from_numpy(y_train[i]).reshape(1,-1))\n",
    "            # exit(-1)rk\n",
    "            if torch.argmax(prediction) == y_train[i]:\n",
    "                precision += 1\n",
    "            loss = loss_function(prediction, torch.tensor([y_train[i]]).long())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss)\n",
    "        print('第%d轮迭代，loss=%.3f，准确率：%.3f' % (e, loss_list[-1],precision/60000))\n",
    "        ##使用eva1()将模型设置为“推理模式”\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d622848-9511-4532-8ee9-0a222f12b01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 1.545, Accuracy: 0.508\n",
      "Epoch 2, Average Loss: 0.396, Accuracy: 0.882\n",
      "Epoch 3, Average Loss: 0.231, Accuracy: 0.934\n",
      "Epoch 4, Average Loss: 0.164, Accuracy: 0.952\n",
      "Epoch 5, Average Loss: 0.131, Accuracy: 0.961\n",
      "Epoch 6, Average Loss: 0.112, Accuracy: 0.967\n",
      "Epoch 7, Average Loss: 0.097, Accuracy: 0.971\n",
      "Epoch 8, Average Loss: 0.086, Accuracy: 0.975\n",
      "Epoch 9, Average Loss: 0.078, Accuracy: 0.976\n",
      "Epoch 10, Average Loss: 0.072, Accuracy: 0.978\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      " \n",
      "Model has been converted to ONNX\n",
      " \n",
      "Model has been converted to ONNX\n"
     ]
    }
   ],
   "source": [
    "#采用GPU进行训练\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def data_fetch_preprocessing():\n",
    "    train_image = open('train-images.idx3-ubyte', 'rb')\n",
    "    test_image = open('t10k-images.idx3-ubyte', 'rb')\n",
    "    train_label = open('train-labels.idx1-ubyte', 'rb')\n",
    "    test_label = open('t10k-labels.idx1-ubyte', 'rb')\n",
    "\n",
    "    magic, n = struct.unpack('>II',\n",
    "                             train_label.read(8))\n",
    "    # 原始数据的标签\n",
    "    y_train_label = np.array(np.fromfile(train_label,\n",
    "                                         dtype=np.uint8), ndmin=1)\n",
    "    y_train = np.ones((10, 60000)) * 0.01\n",
    "    for i in range(60000):\n",
    "        y_train[y_train_label[i]][i] = 0.99\n",
    "\n",
    "    # 测试数据的标签\n",
    "    magic_t, n_t = struct.unpack('>II',\n",
    "                                 test_label.read(8))\n",
    "    y_test = np.fromfile(test_label,\n",
    "                         dtype=np.uint8).reshape(10000, 1)\n",
    "    # print(y_train[0])\n",
    "    # 训练数据共有60000个\n",
    "    # print(len(labels))\n",
    "    magic, num, rows, cols = struct.unpack('>IIII', train_image.read(16))\n",
    "    x_train = np.fromfile(train_image, dtype=np.uint8).reshape(len(y_train_label), 784)\n",
    "\n",
    "    magic_2, num_2, rows_2, cols_2 = struct.unpack('>IIII', test_image.read(16))\n",
    "    x_test = np.fromfile(test_image, dtype=np.uint8).reshape(len(y_test), 784)\n",
    "    # print(x_train.shape)\n",
    "    # 可以通过这个函数观察图像\n",
    "    # data=x_train[:,0].reshape(28,28)\n",
    "    # plt.imshow(data,cmap='Greys',interpolation=None)\n",
    "    # plt.show()\n",
    "\n",
    "    # 关闭打开的文件\n",
    "    train_image.close()\n",
    "    train_label.close()\n",
    "    test_image.close()\n",
    "    test_label.close()\n",
    "\n",
    "    return x_train, y_train_label, x_test, y_test\n",
    "\n",
    "\n",
    "class convolution_neural_network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convolution_neural_network, self).__init__()\n",
    "\n",
    "        # 定义卷积层\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0),  # 28x28x1-->24x24x6\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 12x12x6\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),  # 8x8x16\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # 4x4x16\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=256, out_features=120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 获取数据\n",
    "    x_train, y_train, x_test, y_test = data_fetch_preprocessing()\n",
    "    x_train = x_train.reshape(60000, 1, 28, 28)\n",
    "    \n",
    "    # 建立模型实例\n",
    "    model = convolution_neural_network()\n",
    "    \n",
    "    # 加入判断是CPU训练还是GPU训练\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # 超参数\n",
    "    batch_size = 256\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 10\n",
    "    \n",
    "    # 交叉熵损失函数\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # 数据集转换为Tensor并移到GPU\n",
    "    x_train_tensor = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    \n",
    "    # 迭代训练\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "    \n",
    "        for i in range(0, len(x_train), batch_size):\n",
    "            x_batch = x_train_tensor[i:i+batch_size]\n",
    "            y_batch = y_train_tensor[i:i+batch_size]\n",
    "            #print(x_batch)\n",
    "    \n",
    "            prediction = model(x_batch)\n",
    "            loss = loss_function(prediction, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            total_loss += loss.item()\n",
    "            correct_predictions += (torch.argmax(prediction, dim=1) == y_batch).sum().item()\n",
    "    \n",
    "        average_loss = total_loss / (len(x_train) / batch_size)\n",
    "        accuracy = correct_predictions / len(x_train)\n",
    "    \n",
    "        print(f'Epoch {epoch+1}, Average Loss: {average_loss:.3f}, Accuracy: {accuracy:.3f}')\n",
    "    # 模型保存\n",
    "    #torch.save(LeNet, 'model.pt')\n",
    "    # 模型加载\n",
    "    #model = torch.load('model.pt')\n",
    "\n",
    "    # 保存模型参数\n",
    "    #torch.save(model.state_dict(), \"model.pt\")\n",
    "    ##使用eva1()将模型设置为“推理模式”\n",
    "    # set the model to inference mode \n",
    "    model.eval() \n",
    "\n",
    "    # 在导出之前将模型移回 CPU\n",
    "    model.to(\"cpu\")\n",
    "    \n",
    "    # Let's create a dummy input tensor\n",
    "    dummy_input = torch.randn(1, 1, 28, 28, requires_grad=True)\n",
    "    \n",
    "    # Export the model\n",
    "    torch.onnx.export(model, dummy_input, \"mnist_model.onnx\",\n",
    "                      export_params=True, opset_version=12,\n",
    "                      do_constant_folding=True,\n",
    "                      input_names=['input'],\n",
    "                      output_names=['output'],\n",
    "                     )\n",
    "    \n",
    "    print(\" \")\n",
    "    print('Model has been converted to ONNX')\n",
    "\n",
    "\n",
    "    # # 导出之前的设备设置等代码...\n",
    "    \n",
    "    # # Let's create a dummy input tensor in HWC format\n",
    "    # dummy_input_hwc = torch.randn(1, 28, 28, 1, requires_grad=True)\n",
    "    \n",
    "    # # Transpose the dummy input from HWC to CHW format\n",
    "    # dummy_input_chw = dummy_input_hwc.permute(0, 3, 1, 2)\n",
    "    \n",
    "    # # Export the model\n",
    "    # torch.onnx.export(model, dummy_input_chw, \"Networkhwc.onnx\",\n",
    "    #                   export_params=True, opset_version=12,\n",
    "    #                   do_constant_folding=True,\n",
    "    #                   input_names=['input'],\n",
    "    #                   output_names=['output'])\n",
    "\n",
    "    \n",
    "    print(\" \")\n",
    "    print('Model has been converted to ONNX')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40af7bb4-6e5b-410d-8453-0877c3586cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onnx导出\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "#import trainModel as tm\n",
    "\n",
    "##获取输入参数\n",
    "#data = iter(tm.test_dataloader)\n",
    "#dummy_inputs, labels = next(data)  #直接通过数据集来起作用\n",
    "\n",
    "dummy_inputs = torch.rand(1, 1, 28, 28).float()\n",
    "print(dummy_inputs.shape)\n",
    " \n",
    "##加载模型\n",
    "model = convolution_neural_network()\n",
    "model.load_state_dict(torch.load(\"model.pt\"))\n",
    "\n",
    "#print(model)\n",
    " \n",
    " \n",
    "##加载的模型测试效果\n",
    "outputs = model(dummy_inputs)\n",
    "print(outputs)\n",
    "##预测返回的是两列，第一列是下标就是0-9的值，第二列为预测值，下面的dim=1就是找维度1（第二列）最大值输出\n",
    "# _, predicted = torch.max(outputs.data, dim=1)\n",
    "# print(_)\n",
    "# print(predicted)\n",
    "# outlabels = predicted.numpy().tolist()\n",
    "# print(outlabels)\n",
    "\n",
    "\n",
    "##定义输出输出的参数名\n",
    "input_name = [\"input\"]\n",
    "output_name = [\"output\"] \n",
    "onnx_name = 'mnist_model.onnx'\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_inputs,\n",
    "    onnx_name,\n",
    "    verbose=True,\n",
    "    input_names=input_name,\n",
    "    output_names=output_name,\n",
    "    opset_version=12  # 设置 Opset 版本为 11\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8fbb06-6aaf-454a-89bc-c92f51f3ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 加载 ONNX 模型\n",
    "onnx_path = 'model.onnx'\n",
    "sess = ort.InferenceSession(onnx_path, providers=['CUDAExecutionProvider'])  # 'CPUExecutionProvider'\n",
    "\n",
    "# 创建一个随机输入数据，然后将其转换为 PyTorch 的 Tensor\n",
    "random_input = torch.rand(1, 1, 28, 28).float()\n",
    "#input_data = random_input.cpu().numpy()  # 将 Tensor 转换为 NumPy 数组\n",
    "\n",
    "example_image = cv2.imread('mnist_image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "example_image = np.expand_dims(example_image, axis=0)  # Add channel dimension\n",
    "img=example_image.astype(np.float32)\n",
    "img = np.expand_dims(img, 0).astype(np.float32)\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "# 获取模型的输入名称\n",
    "input_name = sess.get_inputs()[0].name\n",
    "\n",
    "# 进行推理\n",
    "outputs = sess.run(None, {input_name: img})\n",
    "print(outputs)\n",
    "# 提取模型的输出张量，并使用 torch.argmax()\n",
    "output_tensor = torch.tensor(outputs[0])  # 假设第一个输出是你想要获取的\n",
    "argmax_result = torch.argmax(output_tensor)\n",
    "\n",
    "print(argmax_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b675c77-a3b1-4a97-b0c5-2164ed1ce3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#以下使用opencv进行推理\n",
    "import cv2\n",
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 加载数据集\n",
    "def data_fetch_preprocessing():\n",
    "    train_image = open('train-images.idx3-ubyte', 'rb')\n",
    "    test_image = open('t10k-images.idx3-ubyte', 'rb')\n",
    "    train_label = open('train-labels.idx1-ubyte', 'rb')\n",
    "    test_label = open('t10k-labels.idx1-ubyte', 'rb')\n",
    "\n",
    "    magic, n = struct.unpack('>II',\n",
    "                             train_label.read(8))\n",
    "    # 原始数据的标签\n",
    "    y_train_label = np.array(np.fromfile(train_label,\n",
    "                                         dtype=np.uint8), ndmin=1)\n",
    "    y_train = np.ones((10, 60000)) * 0.01\n",
    "    for i in range(60000):\n",
    "        y_train[y_train_label[i]][i] = 0.99\n",
    "\n",
    "    # 测试数据的标签\n",
    "    magic_t, n_t = struct.unpack('>II',\n",
    "                                 test_label.read(8))\n",
    "    y_test = np.fromfile(test_label,\n",
    "                         dtype=np.uint8).reshape(10000, 1)\n",
    "    # print(y_train[0])\n",
    "    # 训练数据共有60000个\n",
    "    # print(len(labels))\n",
    "    magic, num, rows, cols = struct.unpack('>IIII', train_image.read(16))\n",
    "    x_train = np.fromfile(train_image, dtype=np.uint8).reshape(len(y_train_label), 784)\n",
    "\n",
    "    magic_2, num_2, rows_2, cols_2 = struct.unpack('>IIII', test_image.read(16))\n",
    "    x_test = np.fromfile(test_image, dtype=np.uint8).reshape(len(y_test), 784)\n",
    "    # print(x_train.shape)\n",
    "    # 可以通过这个函数观察图像\n",
    "    # data=x_train[:,0].reshape(28,28)\n",
    "    # plt.imshow(data,cmap='Greys',interpolation=None)\n",
    "    # plt.show()\n",
    "\n",
    "    # 关闭打开的文件\n",
    "    train_image.close()\n",
    "    train_label.close()\n",
    "    test_image.close()\n",
    "    test_label.close()\n",
    "\n",
    "    return x_train, y_train_label, x_test, y_test\n",
    "# 要抽取的图像数量\n",
    "num_samples = 1\n",
    "\n",
    "# 获取数据集长度\n",
    "dataset_length = len(x_test)\n",
    "\n",
    "# 生成随机抽样的索引\n",
    "random_indices = random.sample(range(dataset_length), num_samples)\n",
    "\n",
    "# Load the neural network model\n",
    "model_path = 'model.onnx'\n",
    "net = cv2.dnn.readNet(model_path)\n",
    "\n",
    "# 循环抽取的图像进行推理\n",
    "for i in random_indices:\n",
    "    input_data = x_test[i].astype(np.float32).reshape(28, 28)  # 转换为 float 类型\n",
    "\n",
    "    # 将输入数据转换为 Blob\n",
    "    blob = cv2.dnn.blobFromImage(input_data, scalefactor=1.0, size=(28, 28), mean=0.5, swapRB=False)\n",
    "\n",
    "    # 设置输入数据\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # 进行前向传播\n",
    "    outputs = net.forward()\n",
    "\n",
    "    # 提取模型的输出张量，并使用 np.argmax()\n",
    "    output_tensor = outputs[0]  # 假设第一个输出是你想要获取的\n",
    "    argmax_result = np.argmax(output_tensor)\n",
    "\n",
    "    # 打印输入图像、标签和输出结果\n",
    "    input_image = x_test[i].reshape(28, 28)\n",
    "    true_label = y_test[i][0]\n",
    "    predicted_label = argmax_result\n",
    "\n",
    "    plt.imshow(input_image, cmap='Greys', interpolation=None)\n",
    "    plt.title(f'True Label: {true_label}, Predicted Label: {predicted_label}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70522f6d-e337-4891-8dc0-499dcc2c9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加入计时模块\n",
    "import random\n",
    "import timeit\n",
    "import numpy as np\n",
    "\n",
    "# 要抽取的图像数量\n",
    "num_samples = 1\n",
    "\n",
    "# 获取数据集长度\n",
    "dataset_length = len(x_test)\n",
    "\n",
    "# 生成随机抽样的索引\n",
    "random_indices = random.sample(range(dataset_length), num_samples)\n",
    "\n",
    "# 定义前处理函数\n",
    "def preprocess(input_data):\n",
    "    blob = cv2.dnn.blobFromImage(input_data, scalefactor=1.0, size=(28, 28), mean=0.5, swapRB=False)\n",
    "    return blob\n",
    "\n",
    "# 定义推理函数\n",
    "def inference(net, blob):\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward()\n",
    "    return outputs\n",
    "\n",
    "# 初始化时间列表\n",
    "preprocessing_times = []\n",
    "inference_times = []\n",
    "total_times = []\n",
    "# Load the neural network model\n",
    "model_path = 'model.onnx'\n",
    "net = cv2.dnn.readNet(model_path)\n",
    "# 循环抽取的图像进行推理\n",
    "for i in random_indices:\n",
    "    input_data = x_test[i].astype(np.float32).reshape(28, 28)  # 转换为 float 类型\n",
    "\n",
    "    # 计时前处理时间（毫秒）\n",
    "    preprocessing_time_ms = timeit.timeit(lambda: preprocess(input_data), number=1) * 1000\n",
    "    preprocessing_times.append(preprocessing_time_ms)\n",
    "\n",
    "    # 计时推理时间（毫秒）\n",
    "    inference_time_ms = timeit.timeit(lambda: inference(net, preprocess(input_data)), number=1) * 1000\n",
    "    inference_times.append(inference_time_ms)\n",
    "\n",
    "    # 计算总时间（毫秒）\n",
    "    total_time_ms = preprocessing_time_ms + inference_time_ms\n",
    "    total_times.append(total_time_ms)\n",
    "\n",
    "    # 提取模型的输出张量，并使用 np.argmax()\n",
    "    output_tensor = inference(net, preprocess(input_data))[0]  # 假设第一个输出是你想要获取的\n",
    "    argmax_result = np.argmax(output_tensor)\n",
    "\n",
    "    # 打印计时信息\n",
    "    print(f\"Image {i + 1} - Preprocessing Time: {preprocessing_time_ms:.6f} ms, Inference Time: {inference_time_ms:.6f} ms\")\n",
    "\n",
    "    # 打印输入图像、标签和输出结果\n",
    "    input_image = x_test[i].reshape(28, 28)\n",
    "    true_label = y_test[i][0]\n",
    "    predicted_label = argmax_result\n",
    "        # 保存图像\n",
    "\n",
    "\n",
    "    plt.imshow(input_image, cmap='Greys', interpolation=None)\n",
    "    plt.title(f'True Label: {true_label}, Predicted Label: {predicted_label}')\n",
    "    plt.show()\n",
    "    output_image_path = 'mnist_image.jpg'  # 替换为您的输出路径\n",
    "    #plt.savefig(output_image_path, bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    # 调整颜色通道顺序，然后保存图像\n",
    "    output_image_path = 'mnist_image.jpg'  # 替换为您的输出路径\n",
    "\n",
    "# 将颜色通道顺序从 BGR 调整为 RGB\n",
    "    input_image_rgb = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 保存图像\n",
    "    cv2.imwrite(output_image_path, input_image_rgb)  \n",
    "    \n",
    "# 计算平均时间\n",
    "average_preprocessing_time = np.mean(preprocessing_times)\n",
    "average_inference_time = np.mean(inference_times)\n",
    "average_total_time = np.mean(total_times)\n",
    "\n",
    "print(f\"Average Preprocessing Time: {average_preprocessing_time:.6f} ms\")\n",
    "print(f\"Average Inference Time: {average_inference_time:.6f} ms\")\n",
    "print(f\"Average Total Time: {average_total_time:.6f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d20bb-63af-43f7-9ce9-d3626f7e9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加入计时模块\n",
    "import random\n",
    "import timeit\n",
    "import numpy as np\n",
    "\n",
    "# 要抽取的图像数量\n",
    "num_samples = 2\n",
    "\n",
    "# 获取数据集长度\n",
    "dataset_length = len(x_test)\n",
    "\n",
    "# 生成随机抽样的索引\n",
    "random_indices = random.sample(range(dataset_length), num_samples)\n",
    "\n",
    "# 定义前处理函数\n",
    "def preprocess(input_data):\n",
    "    blob = cv2.dnn.blobFromImage(input_data, scalefactor=1.0, size=(28, 28), mean=0.5, swapRB=False)\n",
    "    return blob\n",
    "\n",
    "# 定义推理函数\n",
    "def inference(net, blob):\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward()\n",
    "    return outputs\n",
    "\n",
    "# 初始化时间列表\n",
    "preprocessing_times = []\n",
    "inference_times = []\n",
    "total_times = []\n",
    "# Load the neural network model\n",
    "model_path = 'model.onnx'\n",
    "net = cv2.dnn.readNet(model_path)\n",
    "# 循环抽取的图像进行推理\n",
    "for i in random_indices:\n",
    "    input_data = x_test[i].astype(np.float32).reshape(28, 28)  # 转换为 float 类型\n",
    "\n",
    "    # 计时前处理时间（毫秒）\n",
    "    preprocessing_time_ms = timeit.timeit(lambda: preprocess(input_data), number=1) * 1000\n",
    "    preprocessing_times.append(preprocessing_time_ms)\n",
    "\n",
    "    # 计时推理时间（毫秒）\n",
    "    inference_time_ms = timeit.timeit(lambda: inference(net, preprocess(input_data)), number=1) * 1000\n",
    "    inference_times.append(inference_time_ms)\n",
    "\n",
    "    # 计算总时间（毫秒）\n",
    "    total_time_ms = preprocessing_time_ms + inference_time_ms\n",
    "    total_times.append(total_time_ms)\n",
    "\n",
    "    # 提取模型的输出张量，并使用 np.argmax()\n",
    "    output_tensor = inference(net, preprocess(input_data))[0]  # 假设第一个输出是你想要获取的\n",
    "    argmax_result = np.argmax(output_tensor)\n",
    "\n",
    "    # 打印计时信息\n",
    "    print(f\"Image {i + 1} - Preprocessing Time: {preprocessing_time_ms:.6f} ms, Inference Time: {inference_time_ms:.6f} ms\")\n",
    "\n",
    "    # 打印输入图像、标签和输出结果\n",
    "    input_image = x_test[i].reshape(28, 28)\n",
    "    true_label = y_test[i][0]\n",
    "    predicted_label = argmax_result\n",
    "\n",
    "    plt.imshow(input_image, cmap='Greys', interpolation=None)\n",
    "    plt.title(f'True Label: {true_label}, Predicted Label: {predicted_label}')\n",
    "    plt.show()\n",
    "\n",
    "# 计算平均时间\n",
    "average_preprocessing_time = np.mean(preprocessing_times)\n",
    "average_inference_time = np.mean(inference_times)\n",
    "average_total_time = np.mean(total_times)\n",
    "\n",
    "print(f\"Average Preprocessing Time: {average_preprocessing_time:.6f} ms\")\n",
    "print(f\"Average Inference Time: {average_inference_time:.6f} ms\")\n",
    "print(f\"Average Total Time: {average_total_time:.6f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "800f0500-ad44-4733-b027-8fca83b340cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13065974414348602 0.3015038073062897\n",
      "cuda:0\n",
      "Epoch 1, Average Loss: 2.266, Accuracy: 0.128\n",
      "Epoch 2, Average Loss: 1.713, Accuracy: 0.361\n",
      "Epoch 3, Average Loss: 0.905, Accuracy: 0.686\n",
      "Epoch 4, Average Loss: 0.367, Accuracy: 0.887\n",
      "Epoch 5, Average Loss: 0.189, Accuracy: 0.943\n",
      "Epoch 6, Average Loss: 0.123, Accuracy: 0.963\n",
      "Epoch 7, Average Loss: 0.091, Accuracy: 0.972\n",
      "Epoch 8, Average Loss: 0.075, Accuracy: 0.978\n",
      "Epoch 9, Average Loss: 0.064, Accuracy: 0.981\n",
      "Epoch 10, Average Loss: 0.054, Accuracy: 0.984\n",
      "Epoch 11, Average Loss: 0.051, Accuracy: 0.985\n",
      "Epoch 12, Average Loss: 0.045, Accuracy: 0.987\n",
      "Epoch 13, Average Loss: 0.040, Accuracy: 0.988\n",
      "Epoch 14, Average Loss: 0.035, Accuracy: 0.990\n",
      "Epoch 15, Average Loss: 0.031, Accuracy: 0.991\n",
      "Epoch 16, Average Loss: 0.028, Accuracy: 0.992\n",
      "Epoch 17, Average Loss: 0.026, Accuracy: 0.993\n",
      "Epoch 18, Average Loss: 0.022, Accuracy: 0.994\n",
      "Epoch 19, Average Loss: 0.022, Accuracy: 0.993\n",
      "Epoch 20, Average Loss: 0.018, Accuracy: 0.995\n",
      "Epoch 21, Average Loss: 0.018, Accuracy: 0.995\n",
      "Epoch 22, Average Loss: 0.015, Accuracy: 0.996\n",
      "Epoch 23, Average Loss: 0.015, Accuracy: 0.996\n",
      "Epoch 24, Average Loss: 0.013, Accuracy: 0.996\n",
      "Epoch 25, Average Loss: 0.012, Accuracy: 0.997\n",
      "Epoch 26, Average Loss: 0.010, Accuracy: 0.998\n",
      "Epoch 27, Average Loss: 0.008, Accuracy: 0.998\n",
      "Epoch 28, Average Loss: 0.008, Accuracy: 0.998\n",
      "Epoch 29, Average Loss: 0.007, Accuracy: 0.999\n",
      "Epoch 30, Average Loss: 0.008, Accuracy: 0.998\n",
      "Epoch 31, Average Loss: 0.006, Accuracy: 0.999\n",
      "Epoch 32, Average Loss: 0.005, Accuracy: 0.999\n",
      "Epoch 33, Average Loss: 0.004, Accuracy: 0.999\n",
      "Epoch 34, Average Loss: 0.003, Accuracy: 1.000\n",
      "Epoch 35, Average Loss: 0.003, Accuracy: 1.000\n",
      "Epoch 36, Average Loss: 0.003, Accuracy: 1.000\n",
      "Epoch 37, Average Loss: 0.002, Accuracy: 1.000\n",
      "Epoch 38, Average Loss: 0.002, Accuracy: 1.000\n",
      "Epoch 39, Average Loss: 0.002, Accuracy: 1.000\n",
      "Epoch 40, Average Loss: 0.002, Accuracy: 1.000\n",
      "Epoch 41, Average Loss: 0.002, Accuracy: 1.000\n",
      "Epoch 42, Average Loss: 0.002, Accuracy: 1.000\n",
      "Epoch 43, Average Loss: 0.002, Accuracy: 1.000\n",
      "Epoch 44, Average Loss: 0.001, Accuracy: 1.000\n",
      "Epoch 45, Average Loss: 0.001, Accuracy: 1.000\n",
      "Epoch 46, Average Loss: 0.001, Accuracy: 1.000\n",
      "Epoch 47, Average Loss: 0.001, Accuracy: 1.000\n",
      "Epoch 48, Average Loss: 0.001, Accuracy: 1.000\n",
      "Epoch 49, Average Loss: 0.001, Accuracy: 1.000\n",
      "Epoch 50, Average Loss: 0.001, Accuracy: 1.000\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      " \n",
      "Model has been converted to ONNX\n"
     ]
    }
   ],
   "source": [
    "#采用GPU进行训练\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "        # Calculate mean and std of the dataset\n",
    "        mean = torch.zeros(1)  # Only one channel for grayscale images\n",
    "        std = torch.zeros(1)\n",
    "        for sample, _ in self.data:\n",
    "            sample = self.transform(sample) if self.transform else sample\n",
    "            mean += sample.mean()\n",
    "            std += sample.std()\n",
    "        mean /= len(self.data)\n",
    "        std /= len(self.data)\n",
    "\n",
    "        # Define a transformation to normalize data using calculated mean and std\n",
    "        self.normalize = transforms.Normalize(mean=mean.item(), std=std.item())\n",
    "        print(mean.item(), std.item())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample, label = self.data[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        sample = self.normalize(sample)  # Apply normalization\n",
    "        return sample, label\n",
    "class convolution_neural_network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convolution_neural_network, self).__init__()\n",
    "\n",
    "        # 定义卷积层\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0),  # 28x28x1-->24x24x6\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 12x12x6\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),  # 8x8x16\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # 4x4x16\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=256, out_features=120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output\n",
    "\n",
    "def train(model, train_loader, loss_function, optimizer, device):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(data)\n",
    "        loss = loss_function(prediction, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        correct_predictions += (torch.argmax(prediction, dim=1) == target).sum().item()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    accuracy = correct_predictions / len(train_loader.dataset)\n",
    "    return average_loss, accuracy\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 超参数\n",
    "    learning_rate = 0.01\n",
    "    num_epochs = 50\n",
    "    batch_size = 2048\n",
    "\n",
    "    # Load MNIST dataset\n",
    "    train_dataset = MNIST(root='./mnist/', train=True, download=True,\n",
    "                          transform=None)  # Don't apply ToTensor transformation here   \n",
    "    # Create a custom dataset\n",
    "    train_dataset_custom = CustomDataset(train_dataset, transform=transforms.ToTensor())\n",
    "    \n",
    "    # Create a DataLoader\n",
    "    train_loader = DataLoader(train_dataset_custom, batch_size=batch_size, shuffle=True, num_workers=10, pin_memory=True)\n",
    "\n",
    "    # 建立模型实例\n",
    "    model = convolution_neural_network()\n",
    "\n",
    "    # 加入判断是CPU训练还是GPU训练\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    model=model.to(device)\n",
    "\n",
    "    # 交叉熵损失函数\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 迭代训练\n",
    "    for epoch in range(num_epochs):\n",
    "        average_loss, accuracy = train(model, train_loader, loss_function, optimizer, device)\n",
    "        print(f'Epoch {epoch+1}, Average Loss: {average_loss:.3f}, Accuracy: {accuracy:.3f}')\n",
    "\n",
    "    # 在导出之前将模型移回 CPU\n",
    "    model.to(\"cpu\")\n",
    "    \n",
    "    # Let's create a dummy input tensor\n",
    "    dummy_input = torch.randn(1, 1, 28, 28, requires_grad=True)\n",
    "    \n",
    "    # Export the model\n",
    "    torch.onnx.export(model, dummy_input, \"mnist_model.onnx\",\n",
    "                      export_params=True, opset_version=12,\n",
    "                      do_constant_folding=True,\n",
    "                      input_names=['input'],\n",
    "                      output_names=['output'],\n",
    "                     )\n",
    "    \n",
    "    print(\" \")\n",
    "    print('Model has been converted to ONNX')\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lightglue] *",
   "language": "python",
   "name": "conda-env-lightglue-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
